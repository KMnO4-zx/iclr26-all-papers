import requests
import json
import time
import csv
from typing import List, Dict, Optional, Union
from urllib.parse import urlencode

try:
    from tqdm import tqdm
except ImportError:
    print("æç¤º: å®‰è£… tqdm åº“ä»¥è·å¾—è¿›åº¦æ¡æ˜¾ç¤º: pip install tqdm")
    # åˆ›å»ºå‡çš„ tqdm å‡½æ•°
    def tqdm(iterable, **kwargs):
        return iterable

# API é…ç½®
API_BASE_URL = "https://api2.openreview.net/notes"
LIMIT = 25  # æ¯é¡µè®ºæ–‡æ•°é‡
INITIAL_DELAY = 0.0  # åˆå§‹è¯·æ±‚å»¶è¿Ÿï¼ˆç§’ï¼‰


PAPER_VENUE = "ICLR 2026"  # å·²æ¥æ”¶è®ºæ–‡çš„ venue æ ‡è¯†

# API è¯·æ±‚å‚æ•°é…ç½®
API_PARAMS = {
    "content.venue": PAPER_VENUE,
    "details": "replyCount,presentation,writable",
    "domain": "ICLR.cc/2026/Conference",
    "invitation": "ICLR.cc/2026/Conference/-/Submission",
    "limit": LIMIT
    # "offset" å‚æ•°ä¼šåœ¨è¯·æ±‚æ—¶åŠ¨æ€æ·»åŠ 
}

# è¯·æ±‚å¤´
HEADERS = {
    "Accept": "application/json,text/*;q=0.99",
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36",
    "Referer": "https://openreview.net/",
    "Origin": "https://openreview.net"
}


class ICLR26Crawler:
    """ICLR 2026 Papers Crawler"""

    def __init__(self, limit: int = 25, delay: float = 0.8):
        """
        åˆå§‹åŒ–çˆ¬è™«

        Args:
            limit: æ¯é¡µè·å–çš„è®ºæ–‡æ•°é‡
            delay: APIè¯·æ±‚å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.limit = limit
        self.delay = delay
        self.total_papers = 0
        self.output_file = ""

    def construct_api_url(self, offset: int = 0) -> str:
        """
        æ„å»ºAPIè¯·æ±‚URL

        Args:
            offset: åˆ†é¡µåç§»é‡

        Returns:
            å®Œæ•´çš„API URL
        """
        # ä½¿ç”¨ API_PARAMS é…ç½®ï¼Œå¹¶åŠ¨æ€æ·»åŠ  offset å‚æ•°
        params = API_PARAMS.copy()
        params["offset"] = offset
        params["limit"] = self.limit  # ä½¿ç”¨å®ä¾‹çš„ limit å€¼
        return f"{API_BASE_URL}?{urlencode(params)}"

    def fetch_page(self, offset: int) -> Optional[Dict]:
        """
        è·å–æŒ‡å®šåˆ†é¡µçš„æ•°æ®

        Args:
            offset: åˆ†é¡µåç§»é‡

        Returns:
            APIå“åº”æ•°æ®æˆ–Noneï¼ˆè¯·æ±‚å¤±è´¥æ—¶ï¼‰
        """
        url = self.construct_api_url(offset)

        try:
            response = requests.get(url, headers=HEADERS, timeout=30)
            response.raise_for_status()

            data = response.json()

            # å¦‚æœæ˜¯ç¬¬ä¸€é¡µï¼Œè·å–æ€»æ•°
            if offset == 0:
                self.total_papers = data.get("count", 0)

            return data

        except requests.exceptions.RequestException as e:
            print(f"\nâŒ è¯·æ±‚å¤±è´¥ (offset={offset}): {e}")
            return None
        except json.JSONDecodeError as e:
            print(f"\nâŒ JSONè§£æå¤±è´¥ (offset={offset}): {e}")
            return None
        except Exception as e:
            print(f"\nâŒ æœªçŸ¥é”™è¯¯ (offset={offset}): {e}")
            return None

    def extract_paper_info(self, paper: Union[Dict, object]) -> Dict:
        """
        ä»è®ºæ–‡å¯¹è±¡ä¸­æå–æ‰€éœ€ä¿¡æ¯

        Args:
            paper: è®ºæ–‡å¯¹è±¡

        Returns:
            åŒ…å«æå–çš„ä¿¡æ¯çš„å­—å…¸
        """
        paper_data = {}
        content = paper.get("content", {})

        # åŸºæœ¬ä¿¡æ¯
        paper_data["id"] = paper.get("id", "")
        paper_data["number"] = paper.get("number")

        # title
        title = content.get("title", {})
        paper_data["title"] = title.get("value", "") if isinstance(title, dict) else (title or "")

        # abstract
        abstract = content.get("abstract", {})
        paper_data["abstract"] = abstract.get("value", "") if isinstance(abstract, dict) else (abstract or "")

        # keywords
        keywords = content.get("keywords", {})
        keywords_list = keywords.get("value", []) if isinstance(keywords, dict) else (keywords if isinstance(keywords, list) else [])
        paper_data["keywords"] = " ".join(keywords_list)

        # primary_area
        primary_area = content.get("primary_area", {})
        paper_data["primary_area"] = primary_area.get("value", "") if isinstance(primary_area, dict) else (primary_area or "")

        # PDF URL
        paper_data["pdf_url"] = f"https://openreview.net/attachment?id={paper_data['id']}&name=pdf" if paper_data["id"] else ""

        # OpenReview URL
        paper_data["openreview_url"] = f"https://openreview.net/forum?id={paper_data['id']}" if paper_data["id"] else ""

        # replyCount
        details = paper.get("details", {})
        paper_data["replyCount"] = details.get("replyCount", 0) if details else 0

        return paper_data

    def process_response(self, data: Dict) -> List[Dict]:
        """
        å¤„ç†APIå“åº”æ•°æ®ï¼Œæå–è®ºæ–‡åˆ—è¡¨

        Args:
            data: APIå“åº”æ•°æ®

        Returns:
            è®ºæ–‡ä¿¡æ¯åˆ—è¡¨
        """
        papers = []
        notes = data.get("notes", [])

        for paper in notes:
            paper_info = self.extract_paper_info(paper)
            papers.append(paper_info)

        return papers

    def fetch_all_papers(self) -> List[Dict]:
        """
        è·å–æ‰€æœ‰è®ºæ–‡æ•°æ®

        Returns:
            æ‰€æœ‰è®ºæ–‡çš„ä¿¡æ¯åˆ—è¡¨
        """
        all_papers = []
        offset = 0
        successful_requests = 0
        failed_requests = 0

        print("=" * 60)
        print(" ICLR 2026 Papers Crawler")
        print("=" * 60)
        print(f"è®ºæ–‡ç±»å‹: {API_PARAMS.get('content.venue')}")
        print("è¾“å‡ºæ ¼å¼: JSON + CSV")
        print("-" * 60)
        print("ğŸ” æ­£åœ¨è·å–ç¬¬ä¸€æ‰¹æ•°æ®ä»¥ç¡®å®šæ€»æ•°é‡...")

        # ç¬¬ä¸€é¡µè¯·æ±‚
        first_page = self.fetch_page(offset)
        if not first_page:
            print("âŒ æ— æ³•è·å–ç¬¬ä¸€æ‰¹æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–APIçŠ¶æ€")
            return []

        print(f"âœ… å‘ç° {self.total_papers} ç¯‡è®ºæ–‡")

        if self.total_papers == 0:
            print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•è®ºæ–‡")
            return []

        total_pages = (self.total_papers + self.limit - 1) // self.limit

        print(f"ğŸ“„ éœ€è¦è·å– {total_pages} é¡µæ•°æ® (æ¯é¡µ {self.limit} ç¯‡)")
        print("â³ å¼€å§‹è·å–æ•°æ®...")
        print("-" * 60)

        try:
            from tqdm import tqdm
            use_tqdm = True
        except ImportError:
            use_tqdm = False

        if use_tqdm:
            pbar = tqdm(total=self.total_papers, desc="è·å–è¿›åº¦", unit="paper")
        else:
            pbar = None

        current_count = 0

        # å¤„ç†ç¬¬ä¸€é¡µæ•°æ®
        papers = self.process_response(first_page)
        all_papers.extend(papers)
        successful_requests += 1
        current_count += len(papers)

        if pbar:
            pbar.update(len(papers))
        else:
            print(f"  è¿›åº¦: {current_count}/{self.total_papers} ç¯‡")

        offset += self.limit

        # å¤„ç†å‰©ä½™é¡µé¢
        while offset < self.total_papers:
            page_data = self.fetch_page(offset)

            if page_data:
                papers = self.process_response(page_data)
                all_papers.extend(papers)
                successful_requests += 1
                current_count += len(papers)

                if pbar:
                    pbar.update(len(papers))
                else:
                    print(f"  è¿›åº¦: {current_count}/{self.total_papers} ç¯‡")
            else:
                failed_requests += 1
                print(f"\nâš ï¸  è·³è¿‡ offset={offset} (è¯·æ±‚å¤±è´¥)")

            offset += self.limit
            time.sleep(min(self.delay + offset * 0.0001, 2.0))

        if pbar:
            pbar.close()

        print("-" * 60)
        print(f"âœ… æ•°æ®è·å–å®Œæˆ!")
        print(f"   - æˆåŠŸ: {successful_requests} é¡µ")
        print(f"   - å¤±è´¥: {failed_requests} é¡µ")
        print(f"   - æ€»è®¡: {len(all_papers)} / {self.total_papers} ç¯‡è®ºæ–‡")

        return all_papers

    def save_as_json(self, papers: List[Dict]) -> None:
        """
        ä¿å­˜æ•°æ®ä¸º JSON æ ¼å¼

        Args:
            papers: è®ºæ–‡æ•°æ®åˆ—è¡¨
        """
        try:
            with open(self.output_file, "w", encoding="utf-8") as f:
                json.dump(papers, f, indent=2, ensure_ascii=False)
            print(f"ğŸ’¾ JSON æ–‡ä»¶å·²ä¿å­˜: {self.output_file}")
            print(f"   æ–‡ä»¶å¤§å°: {len(json.dumps(papers)) / 1024:.2f} KB")
        except Exception as e:
            print(f"âŒ ä¿å­˜ JSON æ–‡ä»¶å¤±è´¥: {e}")

    def save_as_csv(self, papers: List[Dict]) -> None:
        """
        ä¿å­˜æ•°æ®ä¸º CSV æ ¼å¼

        Args:
            papers: è®ºæ–‡æ•°æ®åˆ—è¡¨
        """
        if not papers:
            print("âš ï¸ æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return

        try:
            fieldnames = [
                "id", "number", "title", "abstract",
                "keywords", "primary_area", "pdf_url", "openreview_url", "replyCount"
            ]

            with open(self.output_file, "w", newline="", encoding="utf-8") as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()

                for paper in papers:
                    writer.writerow(paper)

            print(f"ğŸ’¾ CSV æ–‡ä»¶å·²ä¿å­˜: {self.output_file}")

            # è®¡ç®—æ–‡ä»¶å¤§å°
            import os
            file_size = os.path.getsize(self.output_file)
            print(f"   æ–‡ä»¶å¤§å°: {file_size / 1024:.2f} KB")

        except Exception as e:
            print(f"âŒ ä¿å­˜ CSV æ–‡ä»¶å¤±è´¥: {e}")

    def save_data(self, papers: List[Dict]) -> None:
        """
        ä¿å­˜æ•°æ®ä¸º JSON å’Œ CSV ä¸¤ç§æ ¼å¼

        Args:
            papers: è®ºæ–‡æ•°æ®åˆ—è¡¨
        """
        # ä¿å­˜ JSON
        self.output_file = "iclr26_all_papers.json"
        self.save_as_json(papers)

        # ä¿å­˜ CSV
        self.output_file = "iclr26_all_papers.csv"
        self.save_as_csv(papers)


def main():
    """ä¸»å‡½æ•°"""

    try:
        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        crawler = ICLR26Crawler(limit=LIMIT, delay=INITIAL_DELAY)

        # è·å–æ‰€æœ‰è®ºæ–‡
        papers = crawler.fetch_all_papers()

        if papers:
            # ä¿å­˜æ•°æ®
            crawler.save_data(papers)
            print("-" * 60)
            print("âœ¨ æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")
            print("=" * 60)
        else:
            print("âš ï¸ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            return 1

    except KeyboardInterrupt:
        print("\n\nâŒ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        print("âš ï¸ éƒ¨åˆ†æ•°æ®å¯èƒ½å·²è·å–ä½†æœªä¿å­˜")
        return 1
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    exit(main())